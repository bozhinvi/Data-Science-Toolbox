{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy\n",
    "import pdb\n",
    "import math\n",
    "import samples\n",
    "\n",
    "class LossFunction(object):\n",
    "\n",
    "    def computeLossAndGradient(self, y, f):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self, f):\n",
    "        return f\n",
    "\n",
    "class LeastSquares(LossFunction):\n",
    "\n",
    "    def computeLossAndGradient(self, y, f):\n",
    "        v= (f-y)\n",
    "        return (v**2, v+v)\n",
    "\n",
    "\n",
    "\n",
    "class DataSource(object):\n",
    "\n",
    "    def __iter__(self):\n",
    "        raise NotImplementedError('This subclass of DataSource does not implement __iter__(). Something is wrong.')\n",
    "\n",
    "class AdomDataSource(DataSource):\n",
    "\n",
    "    def __init__(self, filename, kind=samples.TRAIN):\n",
    "        self.__filename = filename\n",
    "        self.__kind  = kind\n",
    "        self.__f = open(self.__filename, 'r')\n",
    "\n",
    "    def __iter__(self):\n",
    "\n",
    "        for line in self.__f:\n",
    "            entries = line.split(',')# its comma on these files\n",
    "            #assert(len(entries) == 7)\n",
    "            i = int(entries[0]) - 1\n",
    "            j = int(entries[1]) - 1\n",
    "            c1 = int(entries[2]) - 1\n",
    "            c2  = int(entries[3]) - 1\n",
    "            c3  = int(entries[4]) - 1\n",
    "            c4   = int(entries[5]) - 1\n",
    "            c5  = int(entries[6]) - 1\n",
    "            rating  = int(entries[7])\n",
    "\n",
    "\n",
    "            yield samples.Sample(kind=self.__kind, ind = [i,j, c1, c2, c3, c4, c5 ], y=rating)\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "    def getM(self, j):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def getU(self, i):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def getUandM(self, sample):\n",
    "        return (self.getU(sample.row), self.getM(sample.col))\n",
    "\n",
    "    def getUandMandF(self, sample):\n",
    "        return(self.getU(sample.row), self.getM(sample.col), self.getMF(sample.col))\n",
    "\n",
    "    def getEmptyVector(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def getAllMIDs(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def getAllUIDs(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def updateUandM(self, sample, u, m):\n",
    "        pass\n",
    "\n",
    "\n",
    "class TensorModel(Model):\n",
    "    def __init__(self, nFactors, nDimensions):\n",
    "        self.__modelArrays = []\n",
    "        numpy.random.seed(5)\n",
    "        for nFact, nDims in zip(nFactors, nDimensions):\n",
    "            self.__modelArrays.append(abs(numpy.random.normal(4.0/nFact, 1.5/nFact, size=[nDims, nFact])))\n",
    "\n",
    "        self.__Tensor = 0.1*numpy.random.normal(0/nFact, 1.5, size=[5,5]) # this is a dummy tensor, for the real think uncomment previous line\n",
    "        #self.__Tensor = numpy.ones(nFactors)\n",
    "        #abusing the interface here getU returns now a list of arrays containing the rows specified in ind which is a list\n",
    "    def getU(self, ind):\n",
    "        return [k[i,] for (k,i) in zip(self.__modelArrays, ind)]\n",
    "    #abusing the interface again j is a list of indexes in this case\n",
    "    def getM(self, j):\n",
    "        return self.__Tensor[tuple(j)]\n",
    "\n",
    "    def getOne(self, i, ind):\n",
    "        return self.__modelArrays[i][ind,]\n",
    "\n",
    "    def getUandM(self, sample):\n",
    "        return (self.getU(sample.ind), self.__Tensor)\n",
    "\n",
    "    def getFullModel(self):\n",
    "        return self.__modelArrays\n",
    "\n",
    "\n",
    "class LearningRateStrategy(object):\n",
    "\n",
    "    def getLearningRates(self, sample):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class ConstantLearningRate(LearningRateStrategy):\n",
    "\n",
    "    def __init__(self, lr):\n",
    "        self.learningrate = lr\n",
    "\n",
    "    def getLearningRates(self, sample):\n",
    "        return (self.learningrate, self.learningrate)\n",
    "\n",
    "class LambdaModel(object):\n",
    "\n",
    "    def getLambdas(self, sample):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class dualLambdaModel(LambdaModel):\n",
    "    def __init__(self, lbda, tenlbda):\n",
    "        self.__lbda = lbda\n",
    "        self.__tenlbda = tenlbda\n",
    "\n",
    "    def getLambdas(self, sample):\n",
    "        return (self.__lbda, self.__tenlbda)\n",
    "\n",
    "\n",
    "class ConstantLambdaModel(LambdaModel):\n",
    "\n",
    "    def __init__(self, lbda):\n",
    "        self.__lbda = lbda\n",
    "\n",
    "    def getLambdas(self, sample):\n",
    "        return (self.__lbda, self.__lbda)\n",
    "\n",
    "\n",
    "def l2(v, gradient=None):\n",
    "    value    = numpy.dot(v,v)\n",
    "    gradient = v+v # Should not allocate memory if gradient is given of the right size\n",
    "    return (value, gradient)\n",
    "\n",
    "\n",
    "\n",
    "class DataSink(object):\n",
    "\n",
    "    def append(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def getResults(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class IgnoringSink(DataSink):\n",
    "    def append(self, x):\n",
    "        pass\n",
    "\n",
    "    def getResults(self):\n",
    "        return {}\n",
    "\n",
    "\n",
    "class PrintingSink(DataSink):\n",
    "\n",
    "    def append(self, x):\n",
    "        print (x)\n",
    "\n",
    "    def getResults(self):\n",
    "        return {}\n",
    "\n",
    "class FileSink(DataSink):\n",
    "\n",
    "    def __init__(self, file):\n",
    "        self.__file = file\n",
    "\n",
    "    def append(self, x):\n",
    "        self.__file.write(str(x))\n",
    "        self.__file.write('\\n')\n",
    "\n",
    "    def getResults(self):\n",
    "        return {}\n",
    "\n",
    "\n",
    "class ContextFileSink(DataSink):\n",
    "\n",
    "    def __init__(self, file):\n",
    "        self.__file = file\n",
    "\n",
    "    def append(self, x):\n",
    "        self.__file.writelines(\"%s \" % item for item in x.ind)\n",
    "        self.__file.writelines(\"%s \" % x.y)\n",
    "        self.__file.writelines(\"%s\\n\" % x.rawPrediction)\n",
    "\n",
    "\n",
    "    def getResults(self):\n",
    "        return {}\n",
    "\n",
    "class MetaSink(DataSink):\n",
    "    '''\n",
    "        A DataSink that sends TRAIN, TEST and PREDICT Samples into different\n",
    "        sinks.\n",
    "    '''\n",
    "    def __init__(self, trainSink=IgnoringSink(), testSink=IgnoringSink(), predictSink=IgnoringSink()):\n",
    "        self.trainSink = trainSink\n",
    "        self.testSink = testSink\n",
    "        self.predictSink = predictSink\n",
    "\n",
    "    def append(self, sample):\n",
    "        if sample.kind == samples.TRAIN:\n",
    "            self.trainSink.append(sample)\n",
    "        elif sample.kind == samples.TEST:\n",
    "            self.testSink.append(sample)\n",
    "        elif sample.kind == samples.PREDICT:\n",
    "            self.predictSink.append(sample)\n",
    "        else:\n",
    "            logger.warn('The sample was of unkown kind %s: %s' % (sample.kind, sample))\n",
    "\n",
    "    def getResults(self):\n",
    "        raise NotImplementedError('Calling getResults on a MetaSink is unsupported')\n",
    "\n",
    "\n",
    "class SinkChain(DataSink):\n",
    "    '''\n",
    "        A chain of sinks.\n",
    "        Samples sent to it will on to all sinks in the chain.\n",
    "    '''\n",
    "    def __init__(self, sinks=[]):\n",
    "        self.sinks = list(sinks)\n",
    "\n",
    "\n",
    "    def addSink(self, sink):\n",
    "        self.sinks.append(sink)\n",
    "\n",
    "    def append(self, sample):\n",
    "        map(lambda x: x.append(sample), self.sinks)\n",
    "\n",
    "    def getResults(self):\n",
    "        raise NotImplementedError('Calling getResults on a SinkChain is unsupported')\n",
    "\n",
    "\n",
    "class MAErrorSink(DataSink):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.entries = []\n",
    "\n",
    "    def append(self, x):\n",
    "        if x.hasY():\n",
    "            v = abs(x.y-x.prediction)\n",
    "            self.entries.append(v)\n",
    "\n",
    "    def getMAE(self):\n",
    "        return sum(self.entries) / len(self.entries)\n",
    "\n",
    "    def clear(self):\n",
    "        self.entries = []\n",
    "\n",
    "\n",
    "    def getResults(self):\n",
    "        return {'MAE':self.getMAE()}\n",
    "\n",
    "\n",
    "    rmse = property(getMAE, doc='Mean Absolute Error')\n",
    "\n",
    "\n",
    "\n",
    "class RMSErrorSink(DataSink):\n",
    "\n",
    "    '''\n",
    "        A datasink that computes the rooted mean squared average error.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.entries = []\n",
    "\n",
    "    def append(self, x):\n",
    "        if x.hasY():\n",
    "            v = (x.y-x.prediction) ** 2\n",
    "            self.entries.append(v)\n",
    "\n",
    "    def getRMSE(self):\n",
    "        return numpy.sqrt(sum(self.entries) / len(self.entries))\n",
    "\n",
    "    def clear(self):\n",
    "        self.entries = []\n",
    "\n",
    "    def getResults(self):\n",
    "        return {'RMSE':self.getRMSE()}\n",
    "\n",
    "    rmse = property(getRMSE, doc='Root Mean Squared Error')\n",
    "\n",
    "\n",
    "\n",
    "class OnlineTensorCofi(object):\n",
    "\n",
    "    def __init__(self, model, lossFunction, regularizer, lbdaModel, lrStrategy):\n",
    "        self.__loss       = lossFunction\n",
    "        self.__model      = model\n",
    "        self.__lbdaModel  = lbdaModel\n",
    "        self.__reg        = regularizer\n",
    "        self.__lrStrategy = lrStrategy\n",
    "\n",
    "\n",
    "\n",
    "    def updateSimple(self, sample, ma):\n",
    "\n",
    "        lr_ma, lr_ten = self.__lrStrategy.getLearningRates(sample)\n",
    "        # Update the loss\n",
    "        l, g = self.__loss.computeLossAndGradient(y=sample.y, f=sample.rawPrediction)\n",
    "\n",
    "        l_u, l_m = self.__lbdaModel.getLambdas(sample)\n",
    "        ran = range(len(ma))\n",
    "        for i in ran:\n",
    "         ind = [p for p in ran if p not in [i]]\n",
    "         ma[i] -= lr_ma[i] *( g * self.vecMult(ma, ind) + l_u[i] * ma[i])\n",
    "\n",
    "\n",
    "\n",
    "    def run(self, data, sink=IgnoringSink()):\n",
    "        lp          = self.__loss.predict\n",
    "        updateUandM = self.__model.updateUandM\n",
    "\n",
    "        def process(sample):\n",
    "            ma, ten = self.__model.getUandM(sample)\n",
    "            sample.rawPrediction = self.tenDotSimple(ma, range(len(ma)))\n",
    "            sample.prediction = lp(sample.rawPrediction)\n",
    "            if sample.kind == samples.TRAIN and sample.hasY():\n",
    "                #self.update(sample, ma, ten)\n",
    "                self.updateSimple(sample, ma)\n",
    "\n",
    "            sink.append(sample)\n",
    "\n",
    "        map(process, data)\n",
    "\n",
    "    def tenDotSimple(self, ma, ind):\n",
    "        res = ma[ind[0]] * ma[ind[1]]\n",
    "        for i in ind[2:]:\n",
    "            res = res*ma[i]\n",
    "        return numpy.sum(res)\n",
    "\n",
    "\n",
    "    def vecMult(self, ma, ind):\n",
    "        res = ma[ind[0]] * ma[ind[1]]\n",
    "        for i in ind[2:]:\n",
    "            res = res*ma[i]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss    = LeastSquares()\n",
    "model   = TensorModel(nFactors=[4 ,4 , 4, 4, 4, 4, 4], nDimensions=[84,192, 3, 5, 4, 4, 5])\n",
    "regularizer = l2\n",
    "lbdaModel   = dualLambdaModel( [0.0005/x for x in [84,192, 3, 5, 4, 4, 5]], 0.00001) # 0.001\n",
    "lrStrategy = ConstantLearningRate([0.00001*x for x in [84,192, 3, 5, 4, 4, 5]])\n",
    "o = OnlineTensorCofi(model, loss, regularizer, lbdaModel, lrStrategy)\n",
    "testSrc = [x for x in AdomDataSource('/Users/bozhinvi/dropbox/my_python_scripts/Part_2/fold2-test.csv', kind=samples.TEST)]\n",
    "trainSrc = [x for x in AdomDataSource('/Users/bozhinvi/dropbox/my_python_scripts/Part_2/fold2-train.csv', kind=samples.TRAIN)]\n",
    "sink = MetaSink(trainSink=RMSErrorSink(), testSink=RMSErrorSink(), predictSink=RMSErrorSink() )\n",
    "results = open('result-adom.csv','w')\n",
    "results.write('ITER TRAINMAE TESTMAE \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-0b9f696639ac>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-0b9f696639ac>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print i,\" Train RMSE: \", sink.trainSink.getRMSE(), \"\\n\"\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(20):\n",
    "    o.run(trainSrc, sink)\n",
    "    print i,\" Train RMSE: \", sink.trainSink.getRMSE(), \"\\n\"\n",
    "    o.run(testSrc, sink)\n",
    "    print i,\" Test RMSE: \", sink.testSink.getRMSE(), \"\\n\"\n",
    "    results.write('%s %s %s\\n'%(i, sink.trainSink.getRMSE(), sink.testSink.getRMSE()))\n",
    "\n",
    "    sink.testSink.clear()\n",
    "    sink.trainSink.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
