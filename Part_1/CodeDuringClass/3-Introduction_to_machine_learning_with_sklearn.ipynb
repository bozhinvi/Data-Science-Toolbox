{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%run helper_functions.py\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Titanic Dataset (cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the titanic dataset from the disk\n",
    "dataset = pd.read_csv(\"../data/titanic_clean.csv\")\n",
    "X = dataset.drop('survived', axis = 1)\n",
    "y = dataset.survived\n",
    "\n",
    "# to print stats\n",
    "feature_names = X.columns\n",
    "class_labels = [\"Died\", \"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a model with sklearn\n",
    "(in this case we fit a Decision tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting new data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "# we predict some data\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "#Accuracy\n",
    "print (\"Accuracy (train set) : \", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "cm =  confusion_matrix(y_pred=y_pred, y_true=y, labels=[0,1])\n",
    "print (cm)\n",
    "# Plotting confusion matrix (custom help function)\n",
    "plot_confusion_matrix(cm, class_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print (classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the probabilities per class\n",
    "y_probabilities = model.predict_proba(X)\n",
    "# AUC\n",
    "roc_auc_score(y, y_probabilities[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom plot function\n",
    "get_auc(y, y_probabilities, class_labels, column=1, plot=True) # Helper function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Properly evaluating with a test set..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting in test and train sets, train with train set only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "#### Train with train set\n",
    "model  = DecisionTreeClassifier() # max_leaf_nodes=2...10\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#### Accuracy\n",
    "print (\"Accuracy (training set): \", model.score(X_train, y_train), \"\\n\")\n",
    "\n",
    "#### Evaluate with test set\n",
    "# we predict some data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#### Accuracy\n",
    "print (\"Accuracy (test set): \", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "\n",
    "#### Classification report\n",
    "print (classification_report(y_test, y_pred))\n",
    "\n",
    "####  ROC/AUC\n",
    "# Getting the probabilities per class\n",
    "y_probabilities = model.predict_proba(X_test)\n",
    "# Custom plot function\n",
    "get_auc(y_test, y_probabilities, class_labels, column=1, plot=True) # Help function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validating\n",
    "## Cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = DecisionTreeClassifier() # we can now play with max_depth= 1, 10, 15\n",
    "scores = cross_val_score(model, X, y, cv=10)\n",
    "\n",
    "print(scores)\n",
    "print(\"Mean fold accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation predict\n",
    "Predict the whole dataset in a cross-validated way (to avoid overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "model = DecisionTreeClassifier() # we can now play with max_depth= 1, 10, 15\n",
    "\n",
    "####  We use cross-validation to predict all the data with the best model. \n",
    "y_pred = cross_val_predict(model, X, y)\n",
    "\n",
    "print (\"Accuracy (cross-validated): \", accuracy_score(y, y_pred))\n",
    "\n",
    "####  Classification report\n",
    "print (classification_report(y, y_pred))\n",
    "\n",
    "####  ROC/AUC\n",
    "# Getting the probabilities per class\n",
    "y_probabilities = cross_val_predict(model, X, y, method='predict_proba')\n",
    "# Custom plot function\n",
    "get_auc(y, y_probabilities, class_labels, column=1, plot=True) # Help function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning and Cross Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#### The parameeters to tune (as a dictionary name:values_to_try)\n",
    "params = { \n",
    "           'max_leaf_nodes':  range(2,10),\n",
    "           'max_features'  :  range(1,10)\n",
    "         }\n",
    "\n",
    "#### Grid search\n",
    "model = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(estimator=model, cv = 10, param_grid=params )\n",
    "grid.fit(X, y)\n",
    "\n",
    "####  Summarize the results of the grid search\n",
    "print(\"Best parameters: \", grid.best_estimator_)\n",
    "print(\"Best score: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating further the best found model\n",
    "(cross validation using the best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#### Get the best model from grid search (previous run)\n",
    "model = grid.best_estimator_\n",
    "\n",
    "#### FOLLOW THE SAME PROCESS AS BEFORE\n",
    "#### We use cross-validation to predict all the data with the best model. \n",
    "y_pred = cross_val_predict(model, X, y)\n",
    "\n",
    "#### Accuracy\n",
    "print (\"Accuracy (cross-validated): \", accuracy_score(y, y_pred))\n",
    "\n",
    "####  Classification report\n",
    "print (classification_report(y, y_pred))\n",
    "\n",
    "####  ROC/AUC\n",
    "# Getting the probabilities per class\n",
    "y_probabilities = cross_val_predict(model, X, y, method='predict_proba')\n",
    "# Custom plot function\n",
    "get_auc(y, y_probabilities, class_labels, column=1, plot=True) # Help function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning with final test-set evaluation.\n",
    "- Cross validation to select the best model\n",
    "- Test-set at the end to report the final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = { \n",
    "           'max_leaf_nodes':  range(2,10),\n",
    "           'max_features'  :  range(1,10)\n",
    "         }\n",
    "\n",
    "#### Split the data. \n",
    "#### Train set to find and the best model using grid search\n",
    "#### Test set to report the final accuracy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "####  Grid search\n",
    "model = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(estimator=model, cv = 10, param_grid=params )\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross validated accuracy after tuning: \", grid.best_score_)\n",
    "\n",
    "#### \n",
    "#### After tuning, lets see the performance on a seperate test set\n",
    "y_pred = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "#### Accuracy on test set\n",
    "print (\"Accuracy (test set): \", accuracy_score(y_test, y_pred))\n",
    "# Classification report\n",
    "print (classification_report(y_test, y_pred))\n",
    "\n",
    "####  ROC/AUC on test set\n",
    "# Getting the probabilities per class\n",
    "y_probabilities =  grid.best_estimator_.predict_proba(X_test)\n",
    "# Custom plot function\n",
    "get_auc(y_test, y_probabilities, class_labels, column=1, plot=True) # Help function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = pd.Series(grid.best_estimator_.feature_importances_ ,index=X.columns)\n",
    "important_features.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How to handle class imbalance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_df.quality.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let make it more imbalanced than it is...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_df['quality'] = [1 if q >= 8 else 0 for q in wine_df.quality ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_df.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "X = wine_df.drop('quality', axis =1)\n",
    "y = wine_df.quality\n",
    "X, y = sklearn.utils.shuffle(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model = LogisticRegression()#(class_weight='balanced')\n",
    "y_pred = cross_val_predict(model, X, y)\n",
    "\n",
    "#### Accuracy\n",
    "print (\"Accuracy (cross-validated): \", accuracy_score(y, y_pred))\n",
    "\n",
    "####  Classification report\n",
    "print (classification_report(y, y_pred))\n",
    "\n",
    "\n",
    "#confusion matrix\n",
    "cm =  confusion_matrix(y_pred=y_pred, y_true=y, labels=[0,1])\n",
    "# Plotting confusion matrix (custom help function)\n",
    "plot_confusion_matrix(cm, [\"Bad/Average Wine\", \"Great Wine\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####  ROC/AUC on test set\n",
    "# Getting the probabilities per class\n",
    "y_probabilities = cross_val_predict(model, X, y, method='predict_proba')\n",
    "# Custom plot function\n",
    "get_auc(y, y_probabilities, [0,1], column=1, plot=True) # Help function\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
